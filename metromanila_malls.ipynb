{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc52d670-44a0-48ff-a346-fbabeb21f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to get coordinates from place name\n",
    "def get_coordinates(place_name):\n",
    "    base_url = \"https://nominatim.openstreetmap.org/search\"\n",
    "    params = {\n",
    "        \"q\": place_name,\n",
    "        \"format\": \"json\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    response = requests.get(base_url, params=params)\n",
    "    data = response.json()\n",
    "    if data:\n",
    "        # Extract latitude and longitude from the response\n",
    "        lat = data[0][\"lat\"]\n",
    "        lon = data[0][\"lon\"]\n",
    "        return float(lat), float(lon)\n",
    "    else:\n",
    "        return None,None\n",
    "\n",
    "# Function to format polygon points as a string in the required format\n",
    "def format_polygon_points(polygon_points):\n",
    "    formatted_points = \", \".join([f\"{lon} {lat}\" for lat, lon in polygon_points])\n",
    "    return f\"POLYGON (({formatted_points}))\"\n",
    "\n",
    "# Function to get polygon points from OpenStreetMap\n",
    "def get_polygon_points(place_name):\n",
    "    overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "    overpass_query = f\"\"\"\n",
    "    [out:json];\n",
    "    // Query for the place name\n",
    "    area[name=\"{place_name}\"];\n",
    "    // Output the geometry of the area\n",
    "    out geom;\n",
    "    \"\"\"\n",
    "    response = requests.post(overpass_url, data=overpass_query)\n",
    "    data = response.json()\n",
    "    if 'elements' in data and len(data['elements']) > 0:\n",
    "        element = data['elements'][0]\n",
    "        if 'type' in element and element['type'] == 'way':\n",
    "            # Extract polygon points\n",
    "            polygon_points = [(node['lat'], node['lon']) for node in element['geometry']]\n",
    "            return format_polygon_points(polygon_points)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621124ed-237d-4266-b5da-7f041bb2fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape the Wikipedia page\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_shopping_malls_in_Metro_Manila\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Find the table containing major shopping centers information\n",
    "major_shopping_centers_table = soup.find(\"span\", id=\"Major_shopping_centers\").find_next(\"table\", class_=\"wikitable sortable\")\n",
    "\n",
    "# Find the table containing community malls information\n",
    "community_malls_table = soup.find(\"span\", id=\"Community_malls\").find_next(\"table\", class_=\"wikitable sortable\")\n",
    "\n",
    "# Find the table containing lifestyle malls information\n",
    "lifestyle_malls_table = soup.find(\"span\", id=\"Lifestyle_malls\").find_next(\"table\", class_=\"wikitable sortable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5657fc7c-1c28-40b7-8476-79e737c05349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from major shopping centers table\n",
    "major_shopping_centers_data = []\n",
    "for row in major_shopping_centers_table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "    cells = row.find_all(\"td\")\n",
    "    if cells:\n",
    "        name = cells[0].text.strip()\n",
    "        location = cells[2].text.strip()\n",
    "        developer = cells[3].text.strip().split(\"[\")[0].strip()\n",
    "        \n",
    "        major_shopping_centers_data.append((name, location, developer))\n",
    "\n",
    "# Extract data from community malls table\n",
    "community_mall_data = []\n",
    "for row in community_malls_table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "    cells = row.find_all(\"td\")\n",
    "    if cells:\n",
    "        name = cells[0].text.strip()\n",
    "        location = cells[1].text.strip()\n",
    "        developer = cells[2].text.strip().split(\"[\")[0].strip()\n",
    "        \n",
    "        community_mall_data.append((name, location, developer))\n",
    "\n",
    "# Extract data from lifestyle malls table\n",
    "lifestyle_mall_data = []\n",
    "for row in lifestyle_malls_table.find_all(\"tr\")[1:]:  # Skip header row\n",
    "    cells = row.find_all(\"td\")\n",
    "    if cells:\n",
    "        name = cells[0].text.strip()\n",
    "        location = cells[1].text.strip()\n",
    "        developer = cells[2].text.strip().split(\"[\")[0].strip()\n",
    "    \n",
    "        lifestyle_mall_data.append((name, location, developer))\n",
    "\n",
    "# Prep data for major shopping center\n",
    "\n",
    "cities = [\"Manila\", \"Caloocan\", \"Las Piñas\", \"Makati\", \"Malabon\", \"Mandaluyong\", \"Marikina\", \n",
    "          \"Muntinlupa\", \"Navotas\", \"Parañaque\", \"Pasay\", \"Pasig\", \"Quezon City\", \"San Juan\", \"Taguig\", \"Valenzuela\"]\n",
    "\n",
    "developers = [\"Ayala Land\", \"SM Prime Holdings\", \"Robinsons Land\", \"Filinvest Land\", \"Megaworld Corporation\"]\n",
    "\n",
    "df_major_shopping_centers = pd.DataFrame(major_shopping_centers_data, columns=['mall_name','location','developer'])\n",
    "df_community_mall = pd.DataFrame(community_mall_data, columns=['mall_name','location','developer'])\n",
    "df_lifestyle_mall = pd.DataFrame(lifestyle_mall_data, columns=['mall_name','location','developer'])\n",
    "\n",
    "df = pd.concat([df_major_shopping_centers, df_community_mall, df_lifestyle_mall], ignore_index=True)\n",
    "\n",
    "# city filter\n",
    "for city in cities:\n",
    "    mask = df['location'].str.contains(city, case=False)\n",
    "    df.loc[mask, 'location'] = city\n",
    "\n",
    "# check if it is major corp\n",
    "df['is_major_corp'] = np.where(df['developer'].isin(developers), True, False)\n",
    "\n",
    "df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb862564-2b45-424f-9df3-49377b017fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, mall_name in enumerate(df['mall_name']):\n",
    "    polygon_string = get_polygon_points(mall_name)\n",
    "    if polygon_string:\n",
    "        df.loc[index, 'polygon_string'] = polygon_string\n",
    "    else:\n",
    "        df.loc[index, 'polygon_string'] = f\"Polygon points not found for {mall_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04977b2-7e24-44ab-ac9e-a08e58018c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('metro_manila_malls.csv', sep=',', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
